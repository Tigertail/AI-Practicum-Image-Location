{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7yiluwuDTHj",
    "outputId": "927499bc-ca95-4375-862a-6aa2185914ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Shapely==1.6.4.post2 in /usr/local/lib/python3.10/dist-packages (1.6.4.post2)\n",
      "Requirement already satisfied: pycristoforo in /usr/local/lib/python3.10/dist-packages (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install Shapely==1.6.4.post2\n",
    "#%pip install pycristoforo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cM0hLv136hT0",
    "outputId": "a3c3e14f-5b85-46d2-8079-4872b66ab992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Feature', 'geometry': {'type': 'Point', 'coordinates': [20.976563177308364, 53.22449990827475]}, 'properties': {'point': 1, 'country': 'Poland'}}\n"
     ]
    }
   ],
   "source": [
    "# import pycristoforo as pyc\n",
    "\n",
    "# country_1 = pyc.get_shape(\"Poland\")\n",
    "# country_2 = pyc.get_shape(\"Spain\")\n",
    "\n",
    "# points_1 = pyc.geoloc_generation(country_1, 30, \"Poland\")\n",
    "# points_2 = pyc.geoloc_generation(country_2, 30, \"Spain\")\n",
    "\n",
    "# print(points_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15ezvqbcXufr"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "spain = {\"min_lat\": 38, \"max_lat\": 43, \"min_lon\": -6, \"max_lon\": -1}\n",
    "poland = {\"min_lat\": 51, \"max_lat\": 54, \"min_lon\": 15, \"max_lon\": 23}\n",
    "\n",
    "countries = [spain, poland]\n",
    "num_points_class = 30\n",
    "\n",
    "points = []\n",
    "\n",
    "for idx, country in enumerate(countries):\n",
    "  lats = np.random.uniform(country[\"min_lat\"], country[\"max_lat\"], (num_points_class, 1))\n",
    "  lons = np.random.uniform(country[\"min_lon\"], country[\"max_lon\"], (num_points_class, 1))\n",
    "  heads = np.random.uniform(0, 360, (num_points_class, 1))\n",
    "  label = np.zeros((num_points_class, 1))\n",
    "  label[:,:] = idx\n",
    "  locs = np.hstack((lats, lons, heads, label))\n",
    "  points.append(locs)\n",
    "\n",
    "points = np.vstack(points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gx9qF2ebXPT7"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from google.colab import userdata\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "#gets images \n",
    "ims = []\n",
    "class_names = [\"spain\", \"poland\"]\n",
    "\n",
    "for p in points:\n",
    "  url = \"https://maps.googleapis.com/maps/api/streetview?size=600x300&location=\"+str(p[0])+\",\"+str(p[1])+\"&heading=\"+str(p[2])+\"&radius=25000&source=outdoor&key=\" + userdata.get('StreetAPIKey')\n",
    "  response = requests.get(url)\n",
    "  in_memory_file = io.BytesIO(response.content)\n",
    "  im = Image.open(in_memory_file)\n",
    "  w, h = im.size\n",
    "  im = im.crop((0, 0, w, h - 25))\n",
    "  ims.append((im, p[3]))\n",
    "\n",
    "for idx, (im, label) in enumerate(ims):\n",
    "  im.save(\"datasets/spain_poland/\"+class_names[int(label)]+str(idx)+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqfKh635omlA"
   },
   "outputs": [],
   "source": [
    "for idx, (im, label) in enumerate(ims):\n",
    "  im.save(\"drive/MyDrive/spain_poland/\"+class_names[int(label)]+str(idx)+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import googlemaps\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#Storing latitude/longitude of pictures so we dont pull the same one twice\n",
    "lat_long = []\n",
    "random.seed(4)\n",
    "# api_key = Use personal key here\n",
    "\n",
    "# Reading api key + cities to pull data for\n",
    "parent_folder = os.path.dirname(os.path.dirname(__name__))\n",
    "google_api_key = api_key\n",
    "cities = pd.read_csv(parent_folder + \"Data//CityList.csv\")\n",
    "gmaps = googlemaps.Client(key=google_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_random_location(gmaps, location, parent_folder, lat_long,name = \"\", min_distance = 0.005):\n",
    "    #One degree Latitude = 64 miles, taking 1/100 of that\n",
    "    random_multiplier = 0.05\n",
    "\n",
    "    #Generates random value in range [-0.005, 0.005]\n",
    "    random_lat = (random.random()-0.5) * random_multiplier\n",
    "    random_long = (random.random()-0.5) * random_multiplier\n",
    "    original_lat, original_long = list(location)[0], list(location)[1]\n",
    "    \n",
    "    #Calculating new latitude and longitude values\n",
    "    new_lat, new_long = round(original_lat + random_lat,6), round(original_long + random_long,6)\n",
    "\n",
    "    #Ensuring new coordinates sufficiently far from old oness\n",
    "    while (round(new_lat,3), round(new_long,3)) in guessed_coordinates:\n",
    "        print('redo', [new_lat, new_long])\n",
    "        random_lat = (random.random()-0.5) * random_multiplier\n",
    "        random_long = (random.random()-0.5) * random_multiplier\n",
    "        new_lat, new_long = round(original_lat + random_lat,6), round(original_long + random_long,6)\n",
    "\n",
    "    guessed_coordinates.append((round(new_lat,3), round(new_long,3)))\n",
    "\n",
    "    #Adding coordinate set to previously called list\n",
    "    lat_long.append((round(new_lat, 4), round(new_long, 4)))\n",
    "    new_location = (new_lat, new_long)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_random_location(gmaps, location, parent_folder, lat_long,name = \"\", min_distance = 0.005):\n",
    "\n",
    "    \"\"\"\n",
    "    Takes input city coordinates, adds a random element, and pulls an image from this location\n",
    "    ------------------\n",
    "    INPUT:\n",
    "        gmaps: Google maps object\n",
    "        location: tuple containing latitude and longitude\n",
    "        parent_folder: str containing reference to parent folder\n",
    "        lat_long: list containing all previously called coordinates\n",
    "        min_distance: float containing minimum distance allowable between new old/new coordiantes\n",
    "    ------------------\n",
    "    OUTPUT:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    #One degree Latitude = 64 miles, taking 1/100 of that\n",
    "    random_multiplier = 0.05\n",
    "\n",
    "    #Generates random value in range [-0.005, 0.005]\n",
    "    random_lat = (random.random()-0.5) * random_multiplier\n",
    "    random_long = (random.random()-0.5) * random_multiplier\n",
    "    original_lat, original_long = list(location)[0], list(location)[1]\n",
    "    \n",
    "    #Calculating new latitude and longitude values\n",
    "    new_lat, new_long = round(original_lat + random_lat,6), round(original_long + random_long,6)\n",
    "\n",
    "    #Ensuring new coordinates sufficiently far from old oness\n",
    "    while (round(new_lat,3), round(new_long,3)) in guessed_coordinates:\n",
    "        print('redo', [new_lat, new_long])\n",
    "        random_lat = (random.random()-0.5) * random_multiplier\n",
    "        random_long = (random.random()-0.5) * random_multiplier\n",
    "        new_lat, new_long = round(original_lat + random_lat,6), round(original_long + random_long,6)\n",
    "\n",
    "    guessed_coordinates.append((round(new_lat,3), round(new_long,3)))\n",
    "\n",
    "    #Adding coordinate set to previously called list\n",
    "    lat_long.append((round(new_lat, 4), round(new_long, 4)))\n",
    "    new_location = (new_lat, new_long)\n",
    "\n",
    "    #Calling functions\n",
    "    try:\n",
    "        city, address = convert_long_lat_to_address(gmaps,new_location)\n",
    "        pull_image(gmaps, address,parent_folder,str(new_location), name)\n",
    "    except:\n",
    "        print(\"No Image for Location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ouz0aWJ7pmH9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_files = os.listdir('drive/MyDrive/spain_poland/')\n",
    "img_labels = list(map(lambda x: 0 if 'spain' in x else 1, img_files))\n",
    "img_files = list(map(lambda x: 'drive/MyDrive/spain_poland/'+x, img_files))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(img_files, img_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# preprocessing of images\n",
    "class GeoDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform):\n",
    "        super().__init__()\n",
    "        self.paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.len = len(self.paths)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.paths[index]\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        label = self.labels[index]\n",
    "        return (image, label)\n",
    "\n",
    "\n",
    "train_ds = GeoDataset(X_train, y_train, transform)\n",
    "test_ds = GeoDataset(X_test, y_test, transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds)\n",
    "test_loader = DataLoader(test_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ga7DhSaMzP_3"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size=(5, 5), stride=2, padding=1)\n",
    "    self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size=(5, 5), stride=2, padding=1)\n",
    "    self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size=(3, 3), padding=1)\n",
    "\n",
    "    # after the above convolutions on a 600x275 image with 3 channels,\n",
    "    # we should have a 149x68 image with 64 channels\n",
    "    self.fc1 = nn.Linear(in_features= 64 * 149 * 68, out_features=500)\n",
    "    self.fc2 = nn.Linear(in_features=500, out_features=50)\n",
    "    self.fc3 = nn.Linear(in_features=50, out_features=2)\n",
    "\n",
    "  def forward(self, X):\n",
    "\n",
    "      X = F.relu(self.conv1(X))\n",
    "      #X = F.max_pool2d(X, 2)\n",
    "\n",
    "      X = F.relu(self.conv2(X))\n",
    "      #X = F.max_pool2d(X, 2)\n",
    "\n",
    "      X = F.relu(self.conv3(X))\n",
    "      #X = F.max_pool2d(X, 2)\n",
    "\n",
    "      X = X.view(X.shape[0], -1)\n",
    "      X = F.relu(self.fc1(X))\n",
    "      X = F.relu(self.fc2(X))\n",
    "      X = self.fc3(X)\n",
    "\n",
    "      return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xU2Q-Qi33o1Q",
    "outputId": "b7c08357-b8a1-42cf-e1ce-6d9a7ddd6c92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................\n",
      " --- Epoch: 0, train loss: 1.1933, train acc: 0.4792, time: 345.3464891910553\n",
      "Epoch: 0, test loss: 0.6802, test acc: 0.6667, time: 349.7984585762024\n",
      "\n",
      "................................................\n",
      " --- Epoch: 1, train loss: 0.7614, train acc: 0.5208, time: 658.8543744087219\n",
      "Epoch: 1, test loss: 0.6728, test acc: 0.6667, time: 660.7695319652557\n",
      "\n",
      "................................................\n",
      " --- Epoch: 2, train loss: 0.7826, train acc: 0.4583, time: 959.3032774925232\n",
      "Epoch: 2, test loss: 0.6747, test acc: 0.6667, time: 962.321771144867\n",
      "\n",
      "................................................\n",
      " --- Epoch: 3, train loss: 0.7825, train acc: 0.4792, time: 1284.8746178150177\n",
      "Epoch: 3, test loss: 0.6883, test acc: 0.3333, time: 1287.3642344474792\n",
      "\n",
      "................................................\n",
      " --- Epoch: 4, train loss: 0.7340, train acc: 0.6042, time: 1610.53945851326\n",
      "Epoch: 4, test loss: 0.6787, test acc: 0.6667, time: 1613.0534069538116\n",
      "\n",
      "................................................\n",
      " --- Epoch: 5, train loss: 0.6975, train acc: 0.5625, time: 1933.02281498909\n",
      "Epoch: 5, test loss: 0.7007, test acc: 0.5833, time: 1935.484426498413\n",
      "\n",
      "................................................\n",
      " --- Epoch: 6, train loss: 0.7020, train acc: 0.5833, time: 2278.86013007164\n",
      "Epoch: 6, test loss: 0.6818, test acc: 0.6667, time: 2282.1358234882355\n",
      "\n",
      "................................................\n",
      " --- Epoch: 7, train loss: 0.6829, train acc: 0.5417, time: 2625.454219341278\n",
      "Epoch: 7, test loss: 0.6577, test acc: 0.7500, time: 2627.6773841381073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "epochs = 8\n",
    "start = time.time()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "  epoch_loss = 0\n",
    "  epoch_accuracy = 0\n",
    "\n",
    "  for X, y in train_loader:\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    preds = model(X)\n",
    "    loss = loss_fn(preds, y)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    accuracy = ((preds.argmax(dim=1) == y).float().mean())\n",
    "    epoch_accuracy += accuracy\n",
    "    epoch_loss += loss\n",
    "    print('.', end='', flush=True)\n",
    "\n",
    "  epoch_accuracy = epoch_accuracy/len(train_loader)\n",
    "  accuracies.append(epoch_accuracy)\n",
    "  epoch_loss = epoch_loss / len(train_loader)\n",
    "  losses.append(epoch_loss)\n",
    "\n",
    "  print(\"\\n --- Epoch: {}, train loss: {:.4f}, train acc: {:.4f}, time: {}\".format(epoch, epoch_loss, epoch_accuracy, time.time() - start))\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "    test_epoch_loss = 0\n",
    "    test_epoch_accuracy = 0\n",
    "\n",
    "    for test_X, test_y in test_loader:\n",
    "\n",
    "      test_preds = model(test_X)\n",
    "      test_loss = loss_fn(test_preds, test_y)\n",
    "\n",
    "      test_epoch_loss += test_loss\n",
    "      test_accuracy = ((test_preds.argmax(dim=1) == test_y).float().mean())\n",
    "      test_epoch_accuracy += test_accuracy\n",
    "\n",
    "    test_epoch_accuracy = test_epoch_accuracy/len(test_loader)\n",
    "    test_epoch_loss = test_epoch_loss / len(test_loader)\n",
    "\n",
    "    print(\"Epoch: {}, test loss: {:.4f}, test acc: {:.4f}, time: {}\\n\".format(epoch, test_epoch_loss, test_epoch_accuracy, time.time() - start))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
